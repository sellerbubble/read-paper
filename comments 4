知识就是拟合。
牢记知识就是过拟合。
知识不同于逻辑推理，没有某种形式上的规律可以归纳或者泛化。
因此模型百分百回答正确某个知识，就代表百分百过拟合。
而过拟合对于内部扰动的敏感度低，对于外部扰动的敏感度高。
过拟合说明计算过程有更多的显著性，其计算数值有更明显的特性

大模型有很多decoding strategy，其目的是通过发现模型在decoding的过程中的一些数值规律并加以应用，来提高模型在知识问题或者推理问题上的准确率。decoding strategy是否算是奇淫巧计呢？
首先我们应该意识到：对模型而言，“知识就是拟合”。百分百的回答正确率就代表百分百的过拟合。这是因为知识，尤其是事实性知识，本身是离散和具体的，并没有类似于逻辑推理的某种可以泛化、归纳的形式化规律。这就导致模型除了过拟合没有其他方式去回答知识问题。
假如现在有两条数据，“古代中国的首都是北京”和“古代中国的首都是南京”。当我们同时将两条数据喂给模型训练时，模型永远不能通过其内在的推理能力学会“北京和南京都曾经是古代中国的首都”这件事。因为当模型回答“古代中国的首都在__"这个问题时，”北京“和”南京“会在logits上进行竞争，表现出来就是模型回答”北京“和”南京“的概率相当，但最终模型一定会输出一个确定性的答案。发生在logits，也就是模型内部计算层面的信息是无法被模型通过cot的能力解决的，这也就是decoding strategy发挥作用的地方。
但是这个例子是否说明了decoding strategy的强大优势呢？
我认为并没有。decoding strategy终究是通过引入inductive bias来获得短暂的收益。由于模型无法感知到自身的计算过程（比如输出的logits），人就参与进来帮助模型总结其计算规律并加以应用，希望能够提高模型的能力。但是，模型的计算规律往往总结自过拟合场景（因为在面对过拟合问题时模型的表现更加稳定），在面对困难问题（也就是欠拟合的任务）时规律会更模糊。decoding strategy经常是将过拟合的规律应用在欠拟合任务上，这也就导致其带来的收益常常并不明显。
因此，能否有一种方法，能够让模型意识到其自身的计算过程，并自发地利用自身的计算规律来帮助其更好地训练和推理呢？（比如让模型能够接受每次计算得到的logits来感知输出的分布）

【PICABENCH: HOW FAR ARE WE FROM PHYSICALLY REALISTIC IMAGE EDITING?】
编辑图片，注意物理相关的信息。比如光照，物理属性，状态转移。
这些需要推理和知识并存的技能。
需要一个强大的推理模型来提供给image edit模型最好的prompt
运动状态转移的能力是否可以让image edit模型成为world model

【SEMANTIC WORLD MODELS】
使用语言建模future state，如何更好地使用语言来精准描述未来状态的变化。
语言是in context learning的基础，但是其并不准确。
语言应该加上图像一起建模future state，也许可以实现in context learning

【MOWM: MIXTURE-OF-WORLD-MODELS FOR EMBODIED PLANNING VIA LATENT-TO-PIXEL FEATURE
MODULATION】使用video预测模型根据text来预测未来状态，并作为信号辅助另一个action模型输出action。
当前工作对text的利用都很简陋。

【when do nueral networks learn world model】世界模型需要学到一个简化的latent variable，这个variable和state changes具有很强的
因果关系。而multi task可以帮助模型更好地找到这样的latent variable。
单一的任务可能很难寻找到正确的latent variable（符合人类对于物理世界的规律认知），而是找到其他并非我们所期望的variable
gemini：“世界模型”这一概念，源于认知科学，指的是一种对外部世界数据生成过程的内在、抽象的表征 。它并非简单的模式匹配，而是旨在恢复产生观测数据的核心、潜在的因果因素
当训练的任务本身是“简单”的，也即任务所在的环境符合某种简洁的物理规律或组合结构，那么任务就是学到一个关于规律或者组合结构的某些简单状态变量的低复杂度函数。这种任务就是好的任务
语言是否是最好的latent variable

【Video-As-Prompt: Unified Semantic Control for
Video Generation】对机器人使用video as prompt很惊艳。构造人手和机器人操作 video pairs。

【metamorph】最工整的UMM。LLM输出的vision token 是以vision encoder编码的结果作为目标的。输出的vision token也需要通过projector投影到llm 维度。
真正做到图像生成和理解的统一。

【Implicit Multimodal Alignment: On the
Generalization of Frozen LLMs to Multimodal Inputs】multimodal inputs 各自有一个小的锥形区域放置其embedding，不同的模态的锥形不同。
（不同模态的embedding相似度都不同）
norm 也能体现token的特点
【PairUni】通过组织相似数据的generation understanding data pairs 用于post training，提高了janus pro的能力。
这说明janus pro的能力处于一种兼容两种任务的比较一般的平衡态，post training可以轻易地更好地提高其两种任务的能力
